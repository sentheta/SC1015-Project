{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b05d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "sb.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ce7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07122d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>172</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>06 TO 10</td>\n",
       "      <td>45</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1986</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>510</td>\n",
       "      <td>ANG MO KIO AVE 8</td>\n",
       "      <td>01 TO 05</td>\n",
       "      <td>44</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1980</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>610</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>06 TO 10</td>\n",
       "      <td>68</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>315000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>474</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 05</td>\n",
       "      <td>67</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1984</td>\n",
       "      <td>320000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3/1/2012</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>604</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>06 TO 10</td>\n",
       "      <td>67</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>321000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     month        town flat_type block        street_name  \\\n",
       "0           0  3/1/2012  ANG MO KIO    2 ROOM   172   ANG MO KIO AVE 4   \n",
       "1           1  3/1/2012  ANG MO KIO    2 ROOM   510   ANG MO KIO AVE 8   \n",
       "2           2  3/1/2012  ANG MO KIO    3 ROOM   610   ANG MO KIO AVE 4   \n",
       "3           3  3/1/2012  ANG MO KIO    3 ROOM   474  ANG MO KIO AVE 10   \n",
       "4           4  3/1/2012  ANG MO KIO    3 ROOM   604   ANG MO KIO AVE 5   \n",
       "\n",
       "  storey_range  floor_area_sqm      flat_model  lease_commence_date  \\\n",
       "0     06 TO 10              45        Improved                 1986   \n",
       "1     01 TO 05              44        Improved                 1980   \n",
       "2     06 TO 10              68  New Generation                 1980   \n",
       "3     01 TO 05              67  New Generation                 1984   \n",
       "4     06 TO 10              67  New Generation                 1980   \n",
       "\n",
       "   resale_price  \n",
       "0      250000.0  \n",
       "1      265000.0  \n",
       "2      315000.0  \n",
       "3      320000.0  \n",
       "4      321000.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"cleaned-Housing.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e8511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de638d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 49101189726.02468\n",
      "R-squared Score: 0.009338818928007475\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "# Include YEAR and LEASE_DATE into X (predictor)\n",
    "data['resale_price'].fillna(0, inplace=True)\n",
    "data = data.dropna(subset=['floor_area_sqm'])\n",
    "\n",
    "X = data[['floor_area_sqm']]\n",
    "y = data['resale_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_reg_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "linear_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = linear_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print out the model performance metrics\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'R-squared Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebc090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcaae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression:\n",
      "Mean Squared Error (MSE): 49101189724.921715\n",
      "R-squared Score: 0.009338818950260785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize the Ridge Regression model\n",
    "# The alpha parameter controls the degree of regularization (larger values imply more regularization)\n",
    "ridge_reg_model = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ridge_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_ridge = ridge_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# Print out the model performance metrics for Ridge Regression\n",
    "print('Ridge Regression:')\n",
    "print(f'Mean Squared Error (MSE): {mse_ridge}')\n",
    "print(f'R-squared Score: {r2_ridge}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fa8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb2f6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Ridge Regression:\n",
      "Mean Squared Error (MSE): 49101131295.81488\n",
      "R-squared Score: 0.009339997810657197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Initialize the Bayesian Ridge Regression model\n",
    "bayesian_ridge_model = BayesianRidge()\n",
    "\n",
    "# Fit the model on the training data\n",
    "bayesian_ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_bayesian = bayesian_ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse_bayesian = mean_squared_error(y_test, y_pred_bayesian)\n",
    "r2_bayesian = r2_score(y_test, y_pred_bayesian)\n",
    "\n",
    "# Print out the model performance metrics for Bayesian Ridge Regression\n",
    "print('Bayesian Ridge Regression:')\n",
    "print(f'Mean Squared Error (MSE): {mse_bayesian}')\n",
    "print(f'R-squared Score: {r2_bayesian}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a8d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f6fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Coefficients: [967.85115515]\n",
      "Bayesian Ridge Regression Coefficients: [967.21147542]\n"
     ]
    }
   ],
   "source": [
    "# For Ridge Regression\n",
    "ridge_coeffs = ridge_reg_model.coef_\n",
    "print(f'Ridge Regression Coefficients: {ridge_coeffs}')\n",
    "\n",
    "# For Bayesian Ridge Regression\n",
    "bayesian_ridge_coeffs = bayesian_ridge_model.coef_\n",
    "print(f'Bayesian Ridge Regression Coefficients: {bayesian_ridge_coeffs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8fc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0782a2c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 44368038553.20795\n"
     ]
    }
   ],
   "source": [
    "df = data\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_cols = ['flat_type', 'storey_range', 'flat_model']\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[['flat_type', 'storey_range', 'flat_model', 'floor_area_sqm']]\n",
    "y = df['resale_price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Gradient Boosting Regressor model\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ba91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1100efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error after removing outliers: 5464626336.649795\n"
     ]
    }
   ],
   "source": [
    "# Define the lower and upper quantile thresholds\n",
    "lower_quantile = 0.25  # 5th percentile\n",
    "upper_quantile = 0.75  # 95th percentile\n",
    "\n",
    "# Filter out the outliers based on the resale price column\n",
    "lower_threshold = df['resale_price'].quantile(lower_quantile)\n",
    "upper_threshold = df['resale_price'].quantile(upper_quantile)\n",
    "cleaned_df = df[(df['resale_price'] >= lower_threshold) & (df['resale_price'] <= upper_threshold)]\n",
    "\n",
    "# Split the cleaned data into features and target variable\n",
    "X = cleaned_df[['flat_type', 'storey_range', 'flat_model', 'floor_area_sqm']]\n",
    "y = cleaned_df['resale_price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Gradient Boosting Regressor model\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error after removing outliers:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917976b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7d1bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21310 entries, 1 to 167349\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           21310 non-null  int64         \n",
      " 1   month                21310 non-null  object        \n",
      " 2   town                 21310 non-null  object        \n",
      " 3   flat_type            21310 non-null  int64         \n",
      " 4   block                21310 non-null  object        \n",
      " 5   street_name          21310 non-null  object        \n",
      " 6   storey_range         21310 non-null  int64         \n",
      " 7   floor_area_sqm       21310 non-null  int64         \n",
      " 8   flat_model           21310 non-null  int64         \n",
      " 9   lease_commence_date  21310 non-null  datetime64[ns]\n",
      " 10  resale_price         21310 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 35642 entries, 0 to 167397\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           35642 non-null  int64         \n",
      " 1   month                35642 non-null  object        \n",
      " 2   town                 35642 non-null  object        \n",
      " 3   flat_type            35642 non-null  int64         \n",
      " 4   block                35642 non-null  object        \n",
      " 5   street_name          35642 non-null  object        \n",
      " 6   storey_range         35642 non-null  int64         \n",
      " 7   floor_area_sqm       35642 non-null  int64         \n",
      " 8   flat_model           35642 non-null  int64         \n",
      " 9   lease_commence_date  35642 non-null  datetime64[ns]\n",
      " 10  resale_price         35642 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 3.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10140 entries, 213 to 167378\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           10140 non-null  int64         \n",
      " 1   month                10140 non-null  object        \n",
      " 2   town                 10140 non-null  object        \n",
      " 3   flat_type            10140 non-null  int64         \n",
      " 4   block                10140 non-null  object        \n",
      " 5   street_name          10140 non-null  object        \n",
      " 6   storey_range         10140 non-null  int64         \n",
      " 7   floor_area_sqm       10140 non-null  int64         \n",
      " 8   flat_model           10140 non-null  int64         \n",
      " 9   lease_commence_date  10140 non-null  datetime64[ns]\n",
      " 10  resale_price         10140 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 950.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24766 entries, 109 to 167310\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           24766 non-null  int64         \n",
      " 1   month                24766 non-null  object        \n",
      " 2   town                 24766 non-null  object        \n",
      " 3   flat_type            24766 non-null  int64         \n",
      " 4   block                24766 non-null  object        \n",
      " 5   street_name          24766 non-null  object        \n",
      " 6   storey_range         24766 non-null  int64         \n",
      " 7   floor_area_sqm       24766 non-null  int64         \n",
      " 8   flat_model           24766 non-null  int64         \n",
      " 9   lease_commence_date  24766 non-null  datetime64[ns]\n",
      " 10  resale_price         24766 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25613 entries, 96 to 167327\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           25613 non-null  int64         \n",
      " 1   month                25613 non-null  object        \n",
      " 2   town                 25613 non-null  object        \n",
      " 3   flat_type            25613 non-null  int64         \n",
      " 4   block                25613 non-null  object        \n",
      " 5   street_name          25613 non-null  object        \n",
      " 6   storey_range         25613 non-null  int64         \n",
      " 7   floor_area_sqm       25613 non-null  int64         \n",
      " 8   flat_model           25613 non-null  int64         \n",
      " 9   lease_commence_date  25613 non-null  datetime64[ns]\n",
      " 10  resale_price         25613 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6604 entries, 111 to 167105\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           6604 non-null   int64         \n",
      " 1   month                6604 non-null   object        \n",
      " 2   town                 6604 non-null   object        \n",
      " 3   flat_type            6604 non-null   int64         \n",
      " 4   block                6604 non-null   object        \n",
      " 5   street_name          6604 non-null   object        \n",
      " 6   storey_range         6604 non-null   int64         \n",
      " 7   floor_area_sqm       6604 non-null   int64         \n",
      " 8   flat_model           6604 non-null   int64         \n",
      " 9   lease_commence_date  6604 non-null   datetime64[ns]\n",
      " 10  resale_price         6604 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 619.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10962 entries, 246 to 167362\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Unnamed: 0           10962 non-null  int64         \n",
      " 1   month                10962 non-null  object        \n",
      " 2   town                 10962 non-null  object        \n",
      " 3   flat_type            10962 non-null  int64         \n",
      " 4   block                10962 non-null  object        \n",
      " 5   street_name          10962 non-null  object        \n",
      " 6   storey_range         10962 non-null  int64         \n",
      " 7   floor_area_sqm       10962 non-null  int64         \n",
      " 8   flat_model           10962 non-null  int64         \n",
      " 9   lease_commence_date  10962 non-null  datetime64[ns]\n",
      " 10  resale_price         10962 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Heloooooo\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert lease_commence_date to datetime\n",
    "df['lease_commence_date'] = pd.to_datetime(df['lease_commence_date'], format='ISO8601')\n",
    "\n",
    "# Filter the dataset for years from 1980 to 2012\n",
    "df_filtered = df[(df['lease_commence_date'] >= datetime(1980, 1, 1)) & (df['lease_commence_date'] <= datetime(2012, 12, 31))]\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df_filtered[['flat_type', 'storey_range', 'flat_model', 'floor_area_sqm']]\n",
    "y = df_filtered['resale_price']\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize an empty dictionary to store SVR models and MSE for each interval\n",
    "models_mse = {}\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over 5-year intervals from 1980 to 2012\n",
    "for year_start in range(1980, 2013, 5):\n",
    "    year_end = year_start + 4\n",
    "    \n",
    "    # Filter the dataset for the current 5-year interval\n",
    "    # Filter the dataset for years from 1980 to 2012\n",
    "    df_interval = df[(df['lease_commence_date'].dt.year >= year_start) & (df['lease_commence_date'].dt.year <= year_end)]\n",
    "\n",
    "    print(df_interval.info())\n",
    "    continue\n",
    "    \n",
    "    # Skip the interval if there is no data\n",
    "    if df_interval.empty:\n",
    "        continue\n",
    "    \n",
    "    # Define features and target variable for the current interval\n",
    "    X_interval = df_interval[['flat_type', 'storey_range', 'flat_model', 'floor_area_sqm']]\n",
    "    y_interval = df_interval['resale_price']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_interval, y_interval, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize Support Vector Regression model\n",
    "    svr_regressor = SVR()\n",
    "    \n",
    "    # Define hyperparameters for randomized search\n",
    "    param_dist = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': [0.01, 0.1, 1]\n",
    "    }\n",
    "    \n",
    "    # Perform randomized search to find the best hyperparameters\n",
    "    random_search = RandomizedSearchCV(svr_regressor, param_dist, cv=3, scoring='neg_mean_squared_error', n_iter=10, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters\n",
    "    best_params = random_search.best_params_\n",
    "    \n",
    "    # Initialize SVR with best hyperparameters\n",
    "    best_svr_regressor = SVR(**best_params)\n",
    "    \n",
    "    # Train the model\n",
    "    best_svr_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_svr_regressor.predict(X_test)\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Store the trained SVR model and MSE for the current interval\n",
    "    models_mse[(year_start, year_end)] = {'model': best_svr_regressor, 'mse': mse}\n",
    "\n",
    "# Print the MSE for each interval\n",
    "for interval, data in models_mse.items():\n",
    "    print(f\"5-year Interval: {interval}, Mean Squared Error: {data['mse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74781df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab0060fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resale_price\n",
      "        floor_area_sqm lease_commence_date\n",
      "0                   45          1986-01-01\n",
      "1                   44          1980-01-01\n",
      "2                   68          1980-01-01\n",
      "3                   67          1984-01-01\n",
      "4                   67          1980-01-01\n",
      "...                ...                 ...\n",
      "167393             131          1987-01-01\n",
      "167394             122          1987-01-01\n",
      "167395             122          1987-01-01\n",
      "167396             146          1987-01-01\n",
      "167397             146          1988-01-01\n",
      "\n",
      "[167398 rows x 2 columns]\n",
      "        resale_price\n",
      "0           250000.0\n",
      "1           265000.0\n",
      "2           315000.0\n",
      "3           320000.0\n",
      "4           321000.0\n",
      "...              ...\n",
      "167393           0.0\n",
      "167394           0.0\n",
      "167395           0.0\n",
      "167396           0.0\n",
      "167397           0.0\n",
      "\n",
      "[167398 rows x 1 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The DType <class 'numpy.dtype[int64]'> could not be promoted by <class 'numpy.dtype[datetime64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[datetime64]'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 41\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Plot (two) trees\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     for i in range(min(2,len(rf.estimators_))):\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#         plt.figure(figsize=(30,15), dpi=300)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#         plot_tree(rf.estimators_[i])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#         plt.show()    \u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#==============================================================#\u001b[39;00m\n\u001b[1;32m     40\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 41\u001b[0m buildRandForest(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresale_price\u001b[39m\u001b[38;5;124m'\u001b[39m,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor_area_sqm\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlease_commence_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m, in \u001b[0;36mbuildRandForest\u001b[0;34m(prediction, predictors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train decision tree\u001b[39;00m\n\u001b[1;32m     14\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m---> 15\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(x_trn, y_trn)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Predict Response corresponding to Predictors\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_trn_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(x_trn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[1;32m    350\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:797\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    793\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    794\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    795\u001b[0m )\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 797\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    800\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The DType <class 'numpy.dtype[int64]'> could not be promoted by <class 'numpy.dtype[datetime64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[datetime64]'>)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def buildRandForest(prediction,predictors):\n",
    "    # Split prediction and predictors data\n",
    "    y = pd.DataFrame(data[prediction])\n",
    "    x = pd.DataFrame(data[predictors])\n",
    "    x_trn,x_tst,y_trn,y_tst = train_test_split(x,y,test_size=0.25)\n",
    "    \n",
    "    print(prediction)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    \n",
    "    # Train decision tree\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(x_trn, y_trn)\n",
    "    \n",
    "    # Predict Response corresponding to Predictors\n",
    "    y_trn_pred = rf.predict(x_trn)\n",
    "    y_tst_pred = rf.predict(x_tst)\n",
    "    \n",
    "    # Check the Goodness of Fit (on Train Data)\n",
    "    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "    print(\"Explained variance\\t:\", rf.score(x_trn,y_trn))\n",
    "    print(\"Mean squared error \\t:\", mean_squared_error(y_trn, y_trn_pred))\n",
    "    print()\n",
    "\n",
    "    # Check the Goodness of Fit (on Test Data)\n",
    "    print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "    print(\"Explained variance \\t:\", rf.score(x_tst,y_tst))\n",
    "    print(\"Mean squared error \\t:\", mean_squared_error(y_tst, y_tst_pred))\n",
    "    print()\n",
    "    \n",
    "    # Plot (two) trees\n",
    "#     for i in range(min(2,len(rf.estimators_))):\n",
    "#         plt.figure(figsize=(30,15), dpi=300)\n",
    "#         plot_tree(rf.estimators_[i])\n",
    "#         plt.show()    \n",
    "#==============================================================#\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "buildRandForest('resale_price',['floor_area_sqm','lease_commence_date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
